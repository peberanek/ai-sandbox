# Desktop Deployment

> [!NOTE]
> Running advanced models of generative AI requires powerful hardware. You may run some smaller models (like [Llama3.2](https://ollama.com/library/llama3.2)) even without GPU. However, the output generation could be slow. At least 16 GB of RAM is recommended.

Follow the [installation guide for Open WebUI](https://docs.openwebui.com/getting-started/quick-start/). If you are not comfortable with using Docker, first install [Ollama](https://ollama.com/download), and then install Open WebUI via pip (`pip install --user open-webui`).
